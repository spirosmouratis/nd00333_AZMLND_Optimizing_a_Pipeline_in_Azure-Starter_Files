# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
Based on the information we are seeing on the data the problem we are getting called to solve is "If an individual
can be accepted or not for a loan application

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
We applied one Logistic Regression from sklearn directly 
and the results were, Accuracy 0.912 with C:53.14 and Max_itter : 1000
The AutoMl best performing model was a VotingEnsemble one
with Accuracy 0.9174. So marginally better the AutoMl wins over but in a industry/business environment both would be acceptable models.


## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
We start by setting up the train.py file where we load split in test and train data and we prepare our data b converting our categorical data to ints and then to dummy vars so we can apply our logistic regression model since log reg is not dealing directly with categorical data as a tree would do.
We use stratify because we have an imbalanced datset when it comes to our target variable and we want to have a nice
distribution of both classes in our train and test sets
On the hyperparameter side we use max_itter as 1000 which is the amount of iterations for the log reg. And C indicated the inverse of regularisation, Itâ€™s a penalty term, meant to disincentivize and regulate against Overfitting.


**What are the benefits of the parameter sampler you chose?**
The random parameter sampler will choose randomly parameters from the potential parameter space and it is not exahustive like the complete grid parameter sampling.
That is decreasing dramatically the time of the training while keeping the accuracy of the model high enough to solve common industry problems.


**What are the benefits of the early stopping policy you chose?**
The BanditPolicy basically states to check the job every X amount iterations here in our case is 2. If the primary metric which we chose is outside of the top 10% range the jon will be terminated. This saves us from continuing to explore hyperparameters that don't show promise of helping reach our target metric.


## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
The automl model is a VotingEnsemble one including the        "ensembled_algorithms": "['LightGBM', 'XGBoostClassifier', 'LightGBM', 'SGD', 'SGD', 'SGD']",
        "ensemble_weights": "[0.4, 0.3333333333333333, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]",



## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
The small amount of differnce in accuracy mentioned above is because of the automated feature engineering and the automated hyperparamater selection of the AutoML. Is the probelm and the dataset was more complicated I am positive the power of AutoML would be visible in the accuracy.



## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
Normalisation of the dataset.
Explore more hyperparameters of the sklearn model.
Try different metrics than accuracy.
A very important area of work for future improvement for the model is ethical. We have to understand if the model
behaves the same for everyone (Women,Men,people of any colour and for minorities). The model will understand the underlining mathimatecal
connections between the data points but if the data points contain social biases inside them then it is the machine learning engineer
who need to counter these biases


## Proof of cluster clean up
The screenshot is up. After I run the command the cluster was deleted but nothing was printed in the cell.